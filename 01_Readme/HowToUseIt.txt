Ways of usage:
1. using exclusively the GUI via docker container 
2. full spectrum via your python environment and editor (suggested) 

1. Docker
#install docker - make sure it works properly

#open CMD
$cd <Path to ADDMo Repo>
$docker image build -t addmo .
$docker container run --publish 8081:8081 -it -v D:/Git_Repos/Data_Driven_Modeling:/ADDMo --name addmocontainer addmo

#open your browser and enter the URL: http://127.0.0.1:8081/
#The GUI should open up; use the tool; interact with ADDMo via the CMD
#If a script runs into an error you have to restart the container 

#To restart the container in cmd:
"strg+c" for stopping the program
$docker container stop addmocontainer
$docker container rm addmocontainer
$docker container run --publish 8081:8081 -it -v D:/Git_Repos/Data_Driven_Modeling:/ADDMo --name addmocontainer addmo

2. Python + Editor
﻿#Install requirements:
﻿
﻿Via setup.py:
﻿Install Anaconda (conda version: 4.8.0)
﻿
﻿Open command line and create an python 3.6 environment via:
﻿$ conda create --name ADDMo python=3.6 
﻿
﻿Type y for accepting to install first packages
﻿$ y
﻿
﻿Activate environment
﻿$ conda activate ADDMo
﻿
﻿Install required packages via:
﻿$ pip install -e <Path to your local ADDMo repo>
﻿
﻿Set the conda environment "ADDMo" as interpreter for e.g. in PyCharm

Via pip by your own:
The used Python version is 3.6.2

Except the regular packages you need to install:
sklearn-pandas 			(https://github.com/scikit-learn-contrib/sklearn-pandas)
hyperopt 			(http://hyperopt.github.io/hyperopt-sklearn/)
scikit-learn (or sklearn) 	(https://scikit-learn.org/stable/install.html)
openpyxl 			(https://openpyxl.readthedocs.io/en/stable/)
pyforms 			(https://pyforms.readthedocs.io/en/v3.0/)
remi 2019.4 (this is the GUI)		(https://github.com/dddomodossola/remi)
statsmodels
-Possible necessities:
	-networkx = 1.11	(https://networkx.github.io/)
	
-------------------------------------------------------------------------------
The program is built like the mainconcept (file in the readme folder), take it as guideline.
Read the comments in the code or the GUI to get more information.

After reading the below instructions, check all documents in this Readme folder as supplemental documents.
-MainConcept - Verknüpfung : Here the theoretical concept of the program is depicted
-ProgramFlowchart.vsdx : Here you can see which methods are available in the program and in which section they are executed
-MethodDescription.doc : This is a list of all methods plus their Input/Output, the theoretical function and their practical function
-DetailedMethodsDescription_CodingPointOfView.xlsx : This is a list of all methods with their attributes and their meaning, and a more detailed description of each method

Understanding the handling of saving the results:
A folder called results is created within the directory of the python files.
Within that folder a four layered folder system is used, the next layer is a subfolder of the respective previous layer.
The folder are created by the program, only their names must be defined:
	(Layer0: "Results", general folder for all results)
	Layer1: "NameOfData", name of the folder used to declare which input data is used for the results within.
	Layer2: "NameOfExperiment", name of the folder in which the results of "DataTuning" are saved, including the "tuned data" which will be the input for model tuning
	Layer3: "NameOfSubTest", name of the folder in which the results of "ModelTuning" are saved, including the trained models which will be the input for only predicting
	Layer4: "NameOfOnlyPredict", name of the folder in which the results of "OnlyPredict" are saved.


Using the GUI:------------------------------------------------------------------------------------------------------------------------
Run GUI_remi.py and see the information within the GUI

Select the respective "tool" via the tabs:

1.The automatic procedure (Auto final bayes: Importing data, tuning data, training the model while automatically
selecting the best: "Model", "Individual Model", "Features" and "Hyperparameters of the model". Also evaluate the models via out-of-sample prediction), 
Necessary steps "Auto final bayes":
	1.Upload input data
	2.Define settings
	3.Run

2.Data tuning: Importing input data, tuning data.
Necessary steps "Data tuning":
	1.Upload input data
	2.Define settings
	3.Run

3.Model tuning: Importing the previously tuned data, training the model with optimizing the hyperparameters and evaluate the model via out-of-sample prediction.
Necessary steps "Model tuning":
	1.Define the folder from which the tuned data shall be loaded
	2.Define settings
	3.Run

4.Only predict: Import previously trained models and their underlying tuned data, predict and evaluate the model with a more sophisticated evaluation method.
Necessary steps "Predict only":
	1.Define the folder from which the trained models (and their respective tuned data) shall be imported
	2.Define settings
	3.Run


Running the scripts directly via the python console:----------------------------------------------------------------------------------
All variables are defined in SharedVariables.py
Executive scripts are:
	-DataTuning.py for tuning the data (achieving the tuned data)
	-ModelTuning.py for tuning the model (with the tuned data as input)
		In the final lines of ModelTuning.py one can define via commmenting and uncommenting,
		whether the automatic procedure (final bayes: training the model while automatically selecting the best: "Model", "Individual Model", "Features" and "Hyperparameters of the model"), 
		the regular procedure (optimizing the hyperparameter of the model),
		or the procedure for using previously trained models to only predict.

Information about the required Input shape:
Input ExcelFile has to be named: "InputData" and saved in the Folder "Data"
Sheet to read in must be the first sheet, with time as first column and all signals and features thereafter (one per column)
The time must be in the format of "pandas.datetimeindex"
Columns must have different names
Each columns has to have a unit, which should be written like: [kwh] if no unit is available write []
The index should be continuously counting(no missing steps)

Set a name of the data and a name of the experiment in order to save your documentation and results (final input data) in a folder named as the data and a subfolder named as the name of experiment.
This allows to go back to this final input data whenever you want. 

Advises on how to understand the entry section in SharedVariables:
Per Method you´ll find:
1.Line: A comment about what the method is or does
2.Line: A variable that decides whether this method will be used or not. (possible entries are: True or False)
Following lines: Only if additional attributes need to be set: The respective attributes, read the comments to understand which entries are valid.
Empty lines separate the methods

Check for the order of how the methods are executed, as each method´s input is the output of the method conducted before

P.s.
1. The multithreading of the hyperopt package doesn`t work if called from the GUI. The corresponding warning message is only an information that multithreading is turned off, still the script works properly. If multi thread is desired it can be applied via the script without the GUI. 
