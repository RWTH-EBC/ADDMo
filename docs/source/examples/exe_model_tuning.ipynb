{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Tuning"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport pandas as pd\nfrom addmo.util.definitions import results_dir_model_tuning, results_dir_data_tuning_auto, results_dir_data_tuning_fixed\nfrom addmo.util.load_save_utils import root_dir\nfrom addmo.util.experiment_logger import LocalLogger\nfrom addmo.util.experiment_logger import WandbLogger\nfrom addmo.util.experiment_logger import ExperimentLogger\nfrom addmo.s3_model_tuning.models.keras_models import SciKerasSequential\nfrom addmo.s3_model_tuning.config.model_tuning_config import ModelTuningExperimentConfig\nfrom addmo.s3_model_tuning.config.model_tuning_config import ModelTunerConfig\nfrom addmo.s3_model_tuning.model_tuner import ModelTuner\nfrom addmo.util.load_save import load_data\nfrom addmo.util.load_save import load_config_from_json\nfrom addmo.util.data_handling import split_target_features\nfrom addmo.s5_insights.model_plots.scatter_plot import scatter\nfrom addmo.util.plotting_utils import save_pdf\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Please define the missing TODOs in the section below according to the docstrings.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nExecutes model tuning process and returns the best model.\nParameters:\n    user_input : str, optional\n        If 'y', the contents of the target results directory will be overwritten.\n        If 'd', the directory contents will be deleted. Default is 'y'.\n    config_exp : DataTuningExperimentConfig\n    config_tuner : ModelTunerConfig\n\"\"\"\nuser_input = 'y'\nconfig_exp = None\nconfig_tuner = None\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Configure the logger\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "LocalLogger.active = True\nif LocalLogger.active:\n    LocalLogger.directory = results_dir_model_tuning( config_exp,user_input)\nWandbLogger.project = \"addmo-test_model_tuning\"\nWandbLogger.active = False\nif WandbLogger.active:\n    WandbLogger.directory = results_dir_model_tuning(config_exp,user_input)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Initialize logging\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "ExperimentLogger.start_experiment(config=config_exp)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Create the model tuner\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model_tuner = ModelTuner(config=config_tuner)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Load the system_data\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "xy_tuned = load_data(config_exp.abs_path_to_data)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Select training and validation period\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if config_exp.start_train_val and config_exp.stop_train_val:\n    xy_tuned_train_val = xy_tuned.loc[config_exp.start_train_val:config_exp.stop_train_val]\nelse:\n    xy_tuned_train_val = xy_tuned\nx_train_val, y_train_val = split_target_features(config_exp.name_of_target, xy_tuned_train_val)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "log start and end of the system_data\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "ExperimentLogger.log({\"xy_tuned_train_val\": pd.concat([xy_tuned_train_val.head(5), xy_tuned_train_val.tail(5)])})\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Tune the models\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model_dict = model_tuner.tune_all_models(x_train_val, y_train_val)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Get the best model\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "best_model_name = model_tuner.get_best_model_name(model_dict)\nbest_model = model_tuner.get_model(model_dict, best_model_name)\ny_pred = best_model.predict(x_train_val)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Log the best model\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if isinstance(best_model, SciKerasSequential):\n    art_type = 'keras'\nelse:\n    art_type = 'joblib'\nname = 'best_model'\nExperimentLogger.log_artifact(best_model, name, art_type)\nsaved_data_name = config_exp.abs_path_to_data.split(\".\")[0]\nExperimentLogger.log_artifact(xy_tuned,saved_data_name , \"system_data\")\nplt = scatter(y_train_val, y_pred, config_exp.name_of_target, best_model.fit_error)\nsave_pdf(plt, os.path.join(LocalLogger.directory, 'model_fit_scatter'))\nplt.show()\n\n\nprint(\"Finished\")\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
