The present tool faces the following challenges:

-Preprocessing of initial data (in some extent)
-Selection of proper training and test data periods 
-Selection and creation of optimal features 
-Selection of a model, the model configuration 
-Hyperparameter tuning 
-Overfitting & underfitting 

The used methods for facing those challenges are:
Preprocessing:
-Resampling* to the desired resolution.
-Initial custom feature selection* before tuning the data.
-Data cleaning: Replaces NaNs and infinite values.
-Scaling and normalizing: RobustScaler, StandardScaler &
no scaling.

Period selection:
-Time series plotting: Visualization of the signal’s time series
for detecting extraordinary patterns or mistakes in the data
via matplotlib.
-Custom period selection*

Feature creation:
-Cross-, cloud- and autocorrelation plotting: Visualization
of correlations for detecting influential lags and gathering
insight into the system’s dependencies via matplotlib.
-Creation of differences*: Creation of feature derivatives.
-Custom featurelag creation*
-Automatic featurelag creation*: Wrapper for automatic creation
of the best lag per feature within a custom lag range.
Each lag is only created if beneficial. The BBOM is based
on the assumption that only one lag per feature has real
informative value.
-Custom ownlag creation*
-Automated time series ownlag creation*: Wrapper for creating
the optimal number of time series ownlags. Ownlags
are added as long as they improve the score. The selection
is based on the assumption that the score is monotonically
increasing with the number of ownlags, till it reaches the
global optimum.

Feature selection:
-Low variance filter: Deletes features with low variance.
-Custom feature selection* of created features.
-Independent component analysis: Separating of superimposed
features.
-Univariate filter: Several search and rating strategies for
univariate filters.
-Embedded recursive feature selection: Embedded multivariate
feature selection, see scikit-learn.org for further information. Number
of features can be both found automatically or set manually.
-Embedded feature selection by threshold: Univariate feature
selection by a custom threshold of importance.
-Wrapper recursive feature selection*: Multivariate wrapper
which iteratively deletes the worst feature of the respective
feature subset as long as it improves the score.

Sample processing:
-Individual model “hourly”*: One model per hour of the day.
-Individual model “weekday & weekend”*: One model for
weekdays and one for weekends.
-Individual model “by feature”*: One model for all samples
with the feature’s values below and one for values above a
certain threshold. The respective feature is user-defined.
-Shuffle: Random shuffle of samples.

Model tuning:
-Model selection*: Exhaustive wrapper for selecting the best
out of all implemented models.
-Recursive prediction*: Enabling multistep ahead prediction
for models with time series and inertia ownlags. Iteratively
feeding the forecast back to the ownlag slots of the input
features.
-Hyperparameter tuning: via bayesian optimization or grid search
-Cross-validation: prevent overfitting

All those methods are applied sequentially while each method
is optional, thus ensuring that any combination can be selected.
The implemented models are “multi layer perceptron”
(ANN), “epsilon support vector regression” (SVR), “random
forest” (RF), “gradient tree boosting” (GB) and “lasso”. The
methodology of train & test set differentiation, hyperparameter
tuning and cross-validation is depicted in "ModelTuningFlowchart.vsdx". Moreover,
the figure illustrates, how “individual model” and “sample
shuffle” are implemented. The implementation includes a
comprehensive documentation of all settings and results via
tables and plots. Additionally, it enables insight to all changes
conducted, while tuning the data, by documenting the data set
after each method field.

The tool is mainly designed to perform modelling on time series data,
via regression and time series analysis.
Nevertheless it can also be used to handle data indexed by an id, 
simply converting the id into a timestamp (pandas.datetimeindex convention).

06.06.2018 what is the tool not able to do:
The tool is single output only (no MIMO).
It has no natively recurrent model, means it only uses ownlags as a regular input for regression analysis (A native recurrent model would be e.g. long short term memory neural networks)
